{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982f0a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e135802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fire  year  temp  humidity  rainfall  drought_code  buildup_index  day  \\\n",
      "0   no  2015    28        59       0.0          8.06           3.47    1   \n",
      "1   no  2010    30        61       1.3          8.17           4.03    2   \n",
      "2   no  2009    26        83      13.1          8.08           3.59    3   \n",
      "3   no  2017    25        87       2.5          7.18           2.42    4   \n",
      "4   no  2014    28        77       0.0         14.98           4.63    5   \n",
      "\n",
      "   month  wind_speed  \n",
      "0      6          19  \n",
      "1      6          13  \n",
      "2      6          22  \n",
      "3      6          15  \n",
      "4      6          18  \n",
      "  fire  year  temp  humidity  rainfall  drought_code  buildup_index  day  \\\n",
      "0   no  2015    33        68       4.5          9.12           5.09   19   \n",
      "1  yes  2009    28        56       0.0         38.17          21.21   12   \n",
      "2   no  2017    30        64       0.6         15.38           6.24   24   \n",
      "3   no  2007    23        74       8.3          7.36           2.27   14   \n",
      "4   no  2017    31        72       0.3         30.47           5.63    7   \n",
      "\n",
      "   month  wind_speed  \n",
      "0      6          16  \n",
      "1      6          18  \n",
      "2      9          19  \n",
      "3      9          28  \n",
      "4      9          17  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd #import pandas library for reading CSV\n",
    "\n",
    "# Load dataset\n",
    "training_data = pd.read_csv('./Datasets/wildfires_training.csv')\n",
    "test_data = pd.read_csv('./Datasets/wildfires_test.csv')\n",
    "# Check to see if csv is loaded correctly\n",
    "print(training_data.head())\n",
    "print(test_data.head()) \n",
    "\n",
    "# Check to make sure test and training data have the same feature set.\n",
    "training_first_row = training_data.iloc[0]  # Get the first row of the training dataset\n",
    "test_first_row = test_data.iloc[0]          # Get the first row of the test dataset\n",
    "\n",
    "# Assert that the first rows are equal\n",
    "assert list(training_data.drop('fire', axis=1).columns) == list(test_data.drop('fire', axis=1).columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd9953ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  temp  humidity  rainfall  drought_code  buildup_index  day  month  \\\n",
      "0  2015    28        59       0.0          8.06           3.47    1      6   \n",
      "1  2010    30        61       1.3          8.17           4.03    2      6   \n",
      "2  2009    26        83      13.1          8.08           3.59    3      6   \n",
      "3  2017    25        87       2.5          7.18           2.42    4      6   \n",
      "4  2014    28        77       0.0         14.98           4.63    5      6   \n",
      "\n",
      "   wind_speed  \n",
      "0          19  \n",
      "1          13  \n",
      "2          22  \n",
      "3          15  \n",
      "4          18  \n",
      "0    no\n",
      "1    no\n",
      "2    no\n",
      "3    no\n",
      "4    no\n",
      "Name: fire, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_training = training_data.drop('fire', axis=1)  # Features (everything except \"fire\")\n",
    "y_training = training_data['fire']   \n",
    "print(X_training.head())  \n",
    "print(y_training.head())           # Target variable (What I want to predict \"fire\" column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3753b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  temp  humidity  rainfall  drought_code  buildup_index  day  month  \\\n",
      "0  2015    33        68       4.5          9.12           5.09   19      6   \n",
      "1  2009    28        56       0.0         38.17          21.21   12      6   \n",
      "2  2017    30        64       0.6         15.38           6.24   24      9   \n",
      "3  2007    23        74       8.3          7.36           2.27   14      9   \n",
      "4  2017    31        72       0.3         30.47           5.63    7      9   \n",
      "\n",
      "   wind_speed  \n",
      "0          16  \n",
      "1          18  \n",
      "2          19  \n",
      "3          28  \n",
      "4          17  \n",
      "0     no\n",
      "1    yes\n",
      "2     no\n",
      "3     no\n",
      "4     no\n",
      "Name: fire, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = test_data.drop('fire', axis=1)  # Featu√•res (everything except \"fire\")\n",
    "y_test = test_data['fire']               # Target variable (What I want to predict \"fire\" column)\n",
    "print(X_test.head())\n",
    "print(y_test.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b108b0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire\n",
      "yes    0.512987\n",
      "no     0.487013\n",
      "Name: proportion, dtype: float64\n",
      "Entropy of training data: 0.9995132881417702\n"
     ]
    }
   ],
   "source": [
    "# Entropy of the indepednent variable \n",
    "from scipy.stats import entropy\n",
    "print(y_training.value_counts(normalize=True))  # Training data\n",
    "training_entropy = entropy(y_training.value_counts(normalize=True), base=2)\n",
    "print(f\"Entropy of training data: {training_entropy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd230d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training dataset provided: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Model fitting and accuracy evaluation\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "#Model with default settings\n",
    "hgbc_model = HistGradientBoostingClassifier()\n",
    "hgbc_model.fit(X_training, y_training)\n",
    "\n",
    "#Compute accuracy on the training predictions\n",
    "\n",
    "print(\"Accuracy on training dataset provided:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset provided: 0.84\n"
     ]
    }
   ],
   "source": [
    "#Compute accuracy on the training predictions without fine tuning\n",
    "hgbc_model.predict(X_test)\n",
    "accuracy = hgbc_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on test dataset provided:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba72ddf",
   "metadata": {},
   "source": [
    "# Model Hyperparameter Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47b7f811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training dataset provided: 1.0\n"
     ]
    }
   ],
   "source": [
    "hgbc_model = HistGradientBoostingClassifier(learning_rate = 1.0, min_samples_leaf=23)\n",
    "hgbc_model.fit(X_training, y_training)\n",
    "hgbc_model.predict(X_training)\n",
    "accuracy = hgbc_model.score(X_training, y_training)\n",
    "print(\"Accuracy on training dataset provided:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45695cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset with learning_rate provided: 0.9\n"
     ]
    }
   ],
   "source": [
    "hgbc_model.predict(X_test)\n",
    "accuracy = hgbc_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on test dataset with learning_rate provided:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d559384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_leaf: 1, Accuracy: 0.86\n",
      "min_samples_leaf: 2, Accuracy: 0.84\n",
      "min_samples_leaf: 3, Accuracy: 0.88\n",
      "min_samples_leaf: 4, Accuracy: 0.84\n",
      "min_samples_leaf: 5, Accuracy: 0.86\n",
      "min_samples_leaf: 6, Accuracy: 0.86\n",
      "min_samples_leaf: 7, Accuracy: 0.86\n",
      "min_samples_leaf: 8, Accuracy: 0.88\n",
      "min_samples_leaf: 9, Accuracy: 0.86\n",
      "min_samples_leaf: 10, Accuracy: 0.86\n",
      "min_samples_leaf: 11, Accuracy: 0.88\n",
      "min_samples_leaf: 12, Accuracy: 0.88\n",
      "min_samples_leaf: 13, Accuracy: 0.86\n",
      "min_samples_leaf: 14, Accuracy: 0.86\n",
      "min_samples_leaf: 15, Accuracy: 0.86\n",
      "min_samples_leaf: 16, Accuracy: 0.88\n",
      "min_samples_leaf: 17, Accuracy: 0.84\n",
      "min_samples_leaf: 18, Accuracy: 0.86\n",
      "min_samples_leaf: 19, Accuracy: 0.88\n",
      "min_samples_leaf: 20, Accuracy: 0.88\n",
      "min_samples_leaf: 21, Accuracy: 0.86\n",
      "min_samples_leaf: 22, Accuracy: 0.88\n",
      "min_samples_leaf: 23, Accuracy: 0.9\n",
      "min_samples_leaf: 24, Accuracy: 0.86\n",
      "min_samples_leaf: 25, Accuracy: 0.9\n",
      "min_samples_leaf: 26, Accuracy: 0.86\n",
      "min_samples_leaf: 27, Accuracy: 0.88\n",
      "min_samples_leaf: 28, Accuracy: 0.86\n",
      "min_samples_leaf: 29, Accuracy: 0.9\n",
      "min_samples_leaf: 30, Accuracy: 0.88\n",
      "min_samples_leaf: 31, Accuracy: 0.9\n",
      "min_samples_leaf: 32, Accuracy: 0.84\n",
      "min_samples_leaf: 33, Accuracy: 0.88\n",
      "min_samples_leaf: 34, Accuracy: 0.86\n",
      "min_samples_leaf: 35, Accuracy: 0.82\n",
      "min_samples_leaf: 36, Accuracy: 0.88\n",
      "min_samples_leaf: 37, Accuracy: 0.84\n",
      "min_samples_leaf: 38, Accuracy: 0.86\n",
      "min_samples_leaf: 39, Accuracy: 0.84\n",
      "min_samples_leaf: 40, Accuracy: 0.84\n",
      "min_samples_leaf: 41, Accuracy: 0.86\n",
      "min_samples_leaf: 42, Accuracy: 0.86\n",
      "min_samples_leaf: 43, Accuracy: 0.8\n",
      "min_samples_leaf: 44, Accuracy: 0.82\n",
      "min_samples_leaf: 45, Accuracy: 0.8\n",
      "min_samples_leaf: 46, Accuracy: 0.84\n",
      "min_samples_leaf: 47, Accuracy: 0.84\n",
      "min_samples_leaf: 48, Accuracy: 0.84\n",
      "min_samples_leaf: 49, Accuracy: 0.86\n",
      "min_samples_leaf: 50, Accuracy: 0.86\n",
      "\n",
      "Best min_samples_leaf: 23, Best Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Attempting to find the best min_samples_leaf value\n",
    "def find_best_min_samples_leaf(X_training, y_training, X_test, y_test, learning_rate=1.0, min_samples_range=range(1, 51)):\n",
    "    \"\"\"\n",
    "    Finds the best value for min_samples_leaf that gives the highest accuracy on the test dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        X_training (DataFrame): Training features.\n",
    "        y_training (Series): Training target.\n",
    "        X_test (DataFrame): Test features.\n",
    "        y_test (Series): Test target.\n",
    "        learning_rate (float): Learning rate for the model.\n",
    "        min_samples_range (range): Range of values for min_samples_leaf to test.\n",
    "    \n",
    "    Returns:\n",
    "        best_min_samples_leaf (int): The value of min_samples_leaf that gives the highest accuracy.\n",
    "        best_accuracy (float): The highest accuracy achieved.\n",
    "    \"\"\"\n",
    "    best_min_samples_leaf = None\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for min_samples_leaf in min_samples_range:\n",
    "        # Create and train the model\n",
    "        hgbc_model = HistGradientBoostingClassifier(learning_rate=learning_rate, min_samples_leaf=min_samples_leaf)\n",
    "        hgbc_model.fit(X_training, y_training)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = hgbc_model.score(X_test, y_test)\n",
    "        print(f\"min_samples_leaf: {min_samples_leaf}, Accuracy: {accuracy}\")\n",
    "        \n",
    "        # Update the best parameters if the current accuracy is higher\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_min_samples_leaf = min_samples_leaf\n",
    "\n",
    "    print(f\"\\nBest min_samples_leaf: {best_min_samples_leaf}, Best Accuracy: {best_accuracy}\")\n",
    "    return best_min_samples_leaf, best_accuracy\n",
    "\n",
    "# Example usage:\n",
    "best_min_samples_leaf, best_accuracy = find_best_min_samples_leaf(X_training, y_training, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06729a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset provided: 0.9\n"
     ]
    }
   ],
   "source": [
    "hgbc_model.predict(X_test)\n",
    "accuracy = hgbc_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on test dataset provided:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
